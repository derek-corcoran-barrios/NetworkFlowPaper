---
title: "Target-based site prioritization under climate change using quadratic network flow"
author: "Derek Corcoran"
output:
  bookdown::pdf_document2:
    keep_tex: true
    fig_caption: true
    toc: false
bibliography: test.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(bookdown)
library(kableExtra)
library(knitr)
library(raster)
library(rasterVis)
library(rworldxtra)
library(sf)
library(tidyverse)
RasterSolsnandes <- readRDS("RasterSolsnandes.rds")
```

# Introduction

Currently, 14.9% of terrestrial area is a part of the global protected area network [@unep2018ngs]. However, most of this areas have not been created using priorization tools developed to maximize species or ecosystems conservation based on current biodiversity patterns [@rodrigues2004effectiveness; @jenkins2015us]. The situation is even worst when we take into account that the range of species will change over time [@araujo2004would; @chen2011rapid; @lenoir2008significant; @regos2016predicting], were several species that are now being protected by these areas might not be protected in the future because of the climate crisis [@alagador2014shifting; @araujo2004would].

Despite the concern about protected area planning, a review @jones2016incorporating shows that more than 90% of the prioritization planing studies that try to incorporate climate change, only take two time steps into account, current climate and the last step of climate. Currently, two of the most used tools for conservation planning are Prioritize and Zonation [@di2014quick; @Hanson2019]. Zonation can be used for conservation prioritization under climate change as conservation features may be explicitly linked through interaction. This allows for simultaneous prioritization of a species current range, its modelled future range, and the connectivity between the two limited by a species’ capacity to disperse.  

```{r}
DF <- data.frame(BLA = c("Considers more than 2 time-slices", "Can add species to the solutions afterwards", "Keep track of species dispersal routes", "Solves for conservation targets", "Considers cost as part of the solution"), Network_Flow = rep("Yes", 5), Zonation = c("No", "No", "Yes", "Yes", "Yes"), Migclim = c("Yes", "Yes", "Yes", "No", "No"), Prioritizr = c("No", "No", "No", "Yes", "Yes"))

colnames(DF) <- c("", "Network flow", "Zonation", "Migclim", "Prioritizr")

kable(DF, "latex", booktabs = T) %>% kable_styling()
```


However, in order for the species to move from areas were they are currently protected to the future protected areas, their route has to be protected as well, that is the biological corridors that they will use [@nunez2013connectivity; @rosenberg1997biological]. Thus, the planification and creation of those biological corridors correspond to adaptive measures to environmental changes that would mitigate the impacts of the climate crisis [@hannah2007protected]. In that context, biological corridors should consider effects of climate crisis, changes in land use and habitat fragmentation, in order to evaluate the factibility of the species reaching future available habitat.

There have been several approaches trying to model biological corridors. Local approaches have focus just in one or a few species [@alagador2014shifting; @cushman2013biological; @gregory2014forecasts] or group of species  [@beier2007linkage; @phillips2008optimizing; @williams2005planning], not being able to be use for planning for lack of species or be in confined spaces, respectively. A continental approach was made by @lawler2013projected, who modelled biological corridors in the Americas. Even when that model was made for close to 3,000 species did not consider species dispersal speed or use the information to build priority areas. Among these articles, the work of @phillips2008optimizing, incorporates the use of the Network Flow optimization method [@Ahuja93] in order to solve the problem expressed by @williams2005planning, generating a solution 33% more efficient than previous optimization methods. This makes this methodology one of the most promising ways of solving conservation planning problems through the use of biological corridors.

In its traditional use, Network flow gives the best possible solution given constrains [@phillips2008optimizing]. If we looked at the solution for a species in a raster, every cell would have a value of either one or zero, where one would be a cell necessary for the conservation of the species or a zero if it is not necessary. This best solution, however, only represents one of the possible solutions to conserve a species, and does not give us any alternatives. in this research we present Quadratic Cost Network Flow as alternative solution, where for every species we would still get a value of one if the cell is irreplaceable for the solution, zero if that cell is not needed, and an intermediate value for cells that are one of many alternative solutions for a given species, this is, for every cell we have an irreplaceability index. Spatial planning is a complex endeavour where agendas and/or needs evolve rapidly and several alternative suboptimal solutions might be needed in order to navigate this complex decisions.

In this article we present a new method of working with network flow on conservation planning using quadratic costs, while at the same time comparing its results and implications with traditional network flow and zonation,  using the Northern Tropical Andes ecorregion as an example.

# Methods

## Area

The studied area was the Northern Tropical Andes, consisting of the countries of Colombia, Venezuela and Ecuador, with a buffer of 200 kilometres around land areas. 

```{r MapArea, cache=TRUE, fig.align='center', fig.cap='Map of Southamerica, the darkened area is the area where the priorization was performed'}
data("countriesHigh")
SA <- st_as_sf(countriesHigh) %>% st_crop(xmin = -91.40638889, ymin = -58.09166667, xmax = -30.93750000, ymax = 12.63611111)  %>% dplyr::filter(REGION == "South America and the Caribbean") %>% st_transform("+proj=stere +lat_0=-22.720833333333335 +lon_0=-61.17194444444445")
sandes <- sf::read_sf("nandes_buff_clip/nandes_buff_clip.shp") %>% st_transform("+proj=stere +lat_0=-22.720833333333335 +lon_0=-61.17194444444445")

ggplot() + geom_sf(data = SA, fill = "darkolivegreen3", color = "white") + geom_sf(data = sandes, fill = "darkgreen", alpha = 0.5) + theme(
  panel.background = element_rect(fill = "#BFD5E3", colour = "#6D9EC1",
                                size = 2, linetype = "solid"),
  panel.grid.major = element_line(size = 0.5, linetype = 'solid',
                                colour = "white"), 
  panel.grid.minor = element_line(size = 0.25, linetype = 'solid',
                                 colour = "white")
  )


```

The studied area is shown in figure \@ref(fig:MapArea) and it encompasses `r  prettyNum(round(as.numeric(st_area(sandes))/1000000,0), big.mark = ",")` square kilometres

## Species

671 species of plants were used for the model, only endemic species were used in this study. A list can be found in the supplementary materials

## Global circulation models

Global Circulation Models (GCMs) are predictive models that use fluid models... In order to select 4 GCMs, GCMComparer application was used \@ref(fig:Diagrama). Distribution models were generated for each GCM using the Dismo Package in R. Then, each model was projected as a binary response (presence-absence) for all decades form 2000 (present) to 2070 completing 8 time slices for each species.

For each species, a network of dispersion into each time-slice was generated using the QuadCostAmpl package, and finally we solved for Network Flow using the AMPL software using the Gurobi solver

```{r Diagrama, fig.cap= "All the steps and programs used in the Optimization"}
knitr::include_graphics("Diag1.png", dpi = 200)
```

Four GCM models were selected to project the species distribution using the GCMcompareR shiny app [@fajardo_javier_2018_2669407], we followed the story-lines approach [@zappa2017storylines] and selected a GCM warmer and wetter, warmer and dryer, colder and wetter, and colder and dryer than the ensemble. The selected models where `r names(RasterSolsnandes)` al the process is shown in in figure \@ref(fig:Diagrama).

## Niche modelling

### BIEN Data Standardization Workflow. 

The BIEN database is generated via a linked workflow that imports and integrates heterogeneous data structures (including Darwin Core (48) , plus a variety of project-specific schemas and exchange formats), and then performs multiple corrections and validations. The BIEN workflow is described at http://bien.nceas.ucsb.edu/bien/tools/ and in the following references (49-53).  In addition to correcting erroneous original content and standardizing variant spellings to a single canonical form, corrections also remove or flag erroneous content when the correct meaning cannot be determined). Validations delete erroneous records and add annotations that can be used to filter low-quality data and data useful for some analyses but not others (e.g., observations of introduced or cultivated species).

The two major classes of corrections are taxonomic name resolution and geographic name resolution. Taxonomy is standardized using the Taxonomic Name Resolution Service (TNRS; (49) ), which corrects spelling errors in scientific names, standardizes variant spelling and updates synonyms to accepted names. Additional code detects cross-code homonyms (e.g. plant and animal species with identical names) and flags non-plant observations for removal. The names of political divisions (e.g. country, state/ province, county/parish) are standardized using the Geographic Name Resolution Service (GNRS; https://github.com/ojalaquellueva/gnrs) which corrects spelling errors and matches codes (e.g., ISO, FIPS), abbreviations, variant spellings and alternative names in multiple languages to standard political divisions in the GeoNames gazetteer (https://www.geonames.org).

The two major classes of validations are geographic validation and species status validation. Checks performed by geographic validations include (1) coordinate values outside coordinate system (e.g., longitudes larger than 180 degrees or smaller than -180), (2) likely erroneous coordinate values (latitude is exactly 0 or 90 or longitude is exactly 0 or 180,  (3) coordinates in the ocean, (4) coordinate matches a centroid (centroid detection) and (5) coordinates outside lowest declared political division (political division validation). Centroid detection and political division validation used administrative boundaries from the Database of Global Administrative Areas (GADM; http://www.gadm.org), with political division names standardized by the GNRS (see above).  Species status validations checked for (1) species falling outside their native ranges and (2) observations of human-cultivated plants. Observations species outside of their native range were identified using the Native Species Resolver (NSR; https://github.com/ojalaquellueva/nsr), which uses published country and state checklists to determine if the observed species is native to the lowest declare political divisions. List of endemic taxa are also used to detect non-native occurrences outside the region of endemism. and endemism data.  Observations were flagged as cultivated based on (1) keywords in the specimen locality data suggesting provenance from a farm or garden, or (2) geographic proximity ($\leq$ 3 km) to a botanical garden or herbarium, or (3) original observation metadata indicating a cultivated origin.

For these analyses we excluded records if (1) they lacked a scientific name resolved to at least the species level; (2) they did not come from a land plant (Embryophyta); (3) they failed one or more geographic validations; (4) the species was flagged as potentially non-native to the region of observation; (5) the plant was flagged as potentially cultivated; 5) the observation did not originate from either plot or specimen data.

### BIEN Data Sources. 

The BIEN data mainly comprise herbarium collections, ecological plots and surveys (53-60), and trait observations.  For details of specimen data sources see Table S2 of Maitner et al. 2017 (50). A full listing of the herbaria data used are given in the Acknowledgements section. The observations in the BIEN database are the product of contributions by 1076 different data contributors, including numerous individual herbaria, data indexers of herbarium or plot data. Of the herbaria, over 550 are listed in Index Herbarium. Additionally, BIEN 4.1 includes data from RAINBIO, TEAM, The Royal Botanical Garden of Sydney, Australia, and NeoTropTree.  Plot data within BIEN are from the CVS, NVS, SALVIAS, VEGBANK, CTFS, FIA, MADIDI, and TEAM data networks and datasets (see http://bien.nceas.ucsb.edu/bien/data-contributors/all/).

A summary of all of the botanical data in the (BIEN 4.1) database include: Total observations: 206,241,288 which stem from 63,498,238 observations from specimen data, 17,430,379 observations fro plot and survey observations. Plot observations originate from 364,477 plots.  Multiple observations of the same species from a single plot were counted as a single ‘plot’ observation. For details of plot data sources  see Table S1 of Maitner et al. 2017 (50). The final number of the total number of specimen observations used in our analyses after passing through our pipeline was 9,345,197.  For each species we counted the total number of occurrences that were recorded in each dataset.

 Vertebrates. Point occurrences for global restricted range bird species (61). Point occurrences for tropical vertebrates (GBIF, VertNet). Occurrences with geovalid coordinates. Occurrences more recent than 1950. Human observations only (no fossil records or museum specimens). Political centroids and locations with zeros removed. Spatial outliers – more than 500km from IUCN range polygon or >98th percentile of latitude + longitude. Expert range maps polygons for all available mammals, birds, reptiles were used as a means of model and occurrence record validation (61-62)

### Species Distribution Models. 

Species distribution models were produced with Maxent (63) for species with over 10 unique occurrence records (i.e. unique 1km grid cells in the modelling domain). Maxent settings followed the recommendations of Merow et al. 2013 and Merow et al. 2014 to produce relatively less complex models (e.g. limiting features to linear, quadratic, and product functions) to minimize overfitting (64-65). Modeling domains were limited to a spatial buffer of 500km within any geovalid occurrence record.  Background sampling for pseudoabsence point was a random sample of 50,000 points. Five model replicates were used in fitting the model. Average of five replicates was used for final species model in baseline climate – and those fitted parameters were used for all projections into future climates. 30% of occurrence records were reserved to assess model performance.

Environmental Predictor Variables. The following bioclimatic variables from downscaled 20-year normals (66) based on pan-tropical correlation analysis and ability to describe the climate for a given location.  When presented with the choice of two variables that were otherwise closely correlated, we selected the variable that were not combinations of temperature and precipitation or relied on monthly segmentation of the yearly climate (e.g. precipitation in the warmest quarter).

* Mean annual temperature (BIO1)
* Mean diurnal temperature range (BIO2) 
* Seasonality of temperature (BIO4)
* Minimum temperature of the coldest month (BIO6)
* Mean annual precipitation (BIO12)
* Seasonality of precipitation (BIO15)

Accumulated Aridity Index. To account for the effect of dry season length and the water deficit experienced by vegetation during dry periods we derived and accumulated aridity index that identifies the maximum duration and accumulated water deficit for consecutive months where potential evapotranspiration exceeds mean monthly precipitation. The accumulated aridity index is the sum of the month aridity (precipitation – PET) for the maximum run of consecutive months where (PET > precipitation).

For each species the species distribution model was fit using the dismo package [@Hijmans_Dismo], using 50,000 random background points and the maxent algorithm [@phillips2006maximum; @merow2013practical]




## Model Description

This model was developed based on the notion of non-overlapping dispersal chains [@williams2005planning], and instead of having a binary solution (to protect or not protect an area), the result will be an index of importance going from zero to one. Here, zero means that there are no chains passing by that spacial point that go from the source to the final destination, and one is a point where chains have to pass through to reach the desired flow.
In order to do this, we follow Network-flow methods [@Ahuja93] to model the survival and dispersion of species along the space and time, using species distribution models and quadratic flow costs to split the flow evenly across alternative paths. Therefore, the resulting flow across an arc is high only if there are few alternatives to use that edge to achieve the target flow.
Even when model takes into account protected areas (cost zero) and human habitat such as cities (cost infinite) in the decision making, both were not included in this exercise to simplify the examples. This is a generalist model which only needs the distribution model of the species projected to each time slice and the maximum dispersal distance for each species.

### Model Formulation

The objective is to minimize the cost

$\underset{Quadcost}{\text{minimize}}$

$$\small Quadcost =  \sum_{i=1}^n{(Cost\times Flow_t)^2}$$

$\text{subject to}$

$$\small \text{Initial Flow} = \sum_{i=1}^n{Flow_{t_1}} = \text{Target paths}$$

$$\small \text{Final Flow} = \sum_{i=1}^n{Flow_{t_{final}}} = \text{Target paths}$$

$$\small \text{Flow capacity} = \sum_{i=1}^n{Flow_{(i,t)}} \leq capacity_{(i,t)}$$


## Network generation

In order to generate the networks de QuadCostAmpl package was used [@Corcoran_Quadcost]


## Linear Network Flow

Model

## Quadratic Network Flow

## Zonation


# Results {-}




```{r}
RasterSolnandes <- readRDS("RasterSolnandes.rds")
RasterSolnandes <- RasterSolnandes/cellStats(RasterSolnandes, "max")
MaskFull <- RasterSolnandes
values(MaskFull) <- ifelse(is.na(values(MaskFull)), NA, 1)
```


```{r}
RasterSolnandes_ln <- readRDS("RasterSolnandes_linear.rds")
RasterSolnandes_ln <- RasterSolnandes_ln/cellStats(RasterSolnandes_ln, "max")
```


```{r}
Zonation1 <- raster("nandes_endemic_rcp85_PA_cc.CAZ_MEBLP1000.wrscr.compressed.tif")
Zonation1 <- Zonation1/cellStats(Zonation1, "max")

MASK <- Zonation1 

values(MASK) <- ifelse(is.na(values(MASK)), NA, 1)

MASK2 <- RasterSolnandes 

values(MASK2) <- ifelse(is.na(values(RasterSolnandes)), NA, 1)


#Zonation2 <- raster("nandes_endemic_rcp85_PA_cc.CAZ_MEBLP1000.rank.compressed.tif")
#Zonation2 <- Zonation2/cellStats(Zonation2, "max")

Sols <- stack(RasterSolnandes, RasterSolnandes_ln, Zonation1)

Sols <- Sols*MASK*MASK2

names(Sols) <- c("Quadratic NF", "Linear NF", "Zonation")

myTheme <- BuRdTheme()
myTheme$panel.background$col = 'gray'
```

```{r AllSols, dev='png', dpi=700, fig.cap= "Coninuous results of the three algorithms, the highest the value the higher the priority, all values go from 0 to 1."}
levelplot(Sols, par.settings = myTheme)
```

```{r}
Sols2 <- Sols
values(Sols2) <- ifelse(is.na(values(Sols2)), 0, values(Sols2))
Sols2 <- Sols2*MaskFull
Quants <- raster::quantile(Sols2, probs = c(0.85))

values(Sols2[[1]]) <- ifelse(values(Sols2[[1]]) > Quants[1,1], 1, 0)
values(Sols2[[2]]) <- ifelse(values(Sols2[[2]]) > Quants[2,1], 1, 0)
values(Sols2[[3]]) <- ifelse(values(Sols2[[3]]) > Quants[3,1], 1, 0)
names(Sols2) <- c("Quadratic NF", "Linear NF", "Zonation")

Areas <- cellStats((Sols2*area(Sols2[[1]])), "sum")

AreaCells <- cellStats(Sols2, "sum")

r <- sum(Sols2)

rsome <- r
values(rsome) <- ifelse(is.na(values(rsome)), NA, ifelse(values(rsome) > 0, 1, 0))
Some <- cellStats(rsome, "sum")

rOne <- r
values(rOne) <- ifelse(is.na(values(rOne)), NA, ifelse(values(rOne) == 1, 1, 0))
One <- cellStats(rOne, "sum")

rTwo <- r
values(rTwo) <- ifelse(is.na(values(rTwo)), NA, ifelse(values(rTwo) == 2, 1, 0))
Two <- cellStats(rTwo, "sum")

rThree <- r
values(rThree) <- ifelse(is.na(values(rThree)), NA, ifelse(values(rThree) == 3, 1, 0))
Three <- cellStats(rThree, "sum")
```

* **For methods:** Since one of the main objectives of priorization methods is to rank the cells within an area, we used Spearman's rho correlation, that estimates the rank-based measure of association. We also calculated a local Spearman correlation on a matrix of five by five cells, in order to figure out if there are some important 


There are two ways of trying to look at the results, as a continuous layer, as in figure \@ref(fig:AllSols), or as a binary solution as in fig \@ref(fig:Binary), where the cells in red are the top 10% ranked cells to be protected. At first glance, the three algorithms have very similar results. In all three methods the Andes mountains appear to have the highest priorities in particular the Northwest Andean montane forests, Eastern Cordillera Real montane forests, Venezuelan Andes montane forests, Cordillera Oriental montane forests, and the Cauca and Magdalena Valley montane forests, outside of the Andes mountains the ecorregions that have the highest priorities are Guianan Highlands moist forests, Pantepui forests & shrub-lands and Cordillera La Costa montane forests. Furthermore, when we look at the top 10% cells selected by the algorithms (Figures \@ref(fig:Binary) and  \@ref(fig:NumberOfTimes)), we see that of all the cells that were selected at least by one algorithm `r paste0(round((Three/Some*100),2), "%")` of the cells were selected by all three algorithm, which show the level of concordance between cells, `r paste0(round((Two/Some*100),2), "%")` were selected by two of the algorithms and only `r paste0(round((One/Some*100),2), "%")` of the cells selected were chosen by only one of the methods.

However, when we look at the Spearman correlation (table \@ref(tab:Corr)), of all three methods we start seeing some important differences, where Quadratic and Linear Network flow have a spearman correlation of 0.92, but both methods have a smaller correlation with zonation, with Quadratic Network Flow having a higher correlation of 0.669, vs linear network flow having a correlation of 0.624 with Zonation. When we look at the local correlation plots (figure \@ref(fig:LocalCorr)), we see that for the most part, the local correlations are all mostly positive, specially between both Network Flow algorithms. There are some blue areas in the figure, when comparing those priorities with zonation. Representing some big discrepancies in local prioritization, that is mostly localized 


when we look at the box-plot of local correlation values (figure \@ref(fig:Boxplot)), we see that the lower whiskers in the comparison of both Network Flow methods with Zonation, are bellow zero





* **For discussion:** One of the main problems at comparing Network Flow vs Zonation, is that Zonation will give a rank to each and every cell in the study area, which is not true for Network Flow. It comes as no surprise that Quadratic Network flow has a higher correlation with Zonation than Linear Network flow, the intended result of quadratic network flow being more similar to zonation than linear network flow. 

### Efficiency comparison (Number of cells)



```{r  Binary, dev='png', dpi=700, fig.cap= "Binary solution for the cells with the top 10% value of ranked priority"}
levelplot(Sols2, par.settings = myTheme)
```

In this example when we calculate the top 10% of protected cells for Quadratic Network Flow we get `r prettyNum(round(AreaCells[1]), big.mark = ",")` cells, `r prettyNum(round(AreaCells[2]), big.mark = ",")` cells for linear Network Flow, and `r prettyNum(round(AreaCells[3]), big.mark = ",")` cells for Zonation.

```{r}
r <- ratify(sum(Sols2))

rat <- levels(r)[[1]]
rat$landcover <- c("Zero",'One', 'Two', 'Three')
rat$class <- c("0",'A1', 'B2', 'C3')
levels(r) <- rat
```

```{r NumberOfTimes, dev='png', dpi=700, fig.cap= "This map shows how many algorithms selected each cell"}
levelplot(r, col.regions=c("#0571b0","#92c5de","#f4a582","#ca0020"), colorkey = list(title = "Number of algorithms"))
```




### Correlation comparison (Spearman)

```{r Corr}
library(corrr)
COR <- as.data.frame(Sols) %>% dplyr::filter(!is.na(Zonation), !is.na(Quadratic.NF)) %>% correlate(use ="pairwise.complete.obs", method = "spearman") %>% rearrange()

kable(COR, "latex", booktabs = T, caption = "Spearman correlation between the rank of the cells of all three methods") %>% kable_styling()
```


```{r}
CORRSTACK <- read_rds("CORRSTACK.rds")
```


```{r LocalCorr, dev='png', dpi=700, fig.cap="Box plot of local correlations between all three different methods of priorization"}

levelplot(CORRSTACK, par.settings = myTheme, layout=c(3, 3))
```

```{r Boxplot, fig.cap="Box plot of local correlations between all three different methods of priorization"}
bwplot(CORRSTACK[[c(2,3,6)]], violin = FALSE)
```


# Discussion



# Disclosure/Conflict-of-Interest Statement {-}



The authors declare that the research was conducted in the absence of any
commercial or financial relationships that could be construed as a potential
conflict of interest.

# Author Contributions {-}


When determining authorship the following criteria should be observed:

 - Substantial contributions to the conception or design of the work; or the
   acquisition, analysis, or interpretation of data for the work; AND
 - Drafting the work or revising it critically for important intellectual
   content; AND
 - Final approval of the version to be published ; AND
 - Agreement to be accountable for all aspects of the work in ensuring that
   questions related to the accuracy or integrity of any part of the work are
   appropriately investigated and resolved.

Contributors who meet fewer than all 4 of the above criteria for authorship
should not be listed as authors, but they should be acknowledged.
(http://www.icmje.org/roles_a.html)


The statement about the authors and contributors can be up to several sentences
long, describing the tasks of individual authors referred to by their initials
and should be included at the end of the manuscript before the References
section.


# Acknowledgments {-}

Funding:

# Supplemental Data 

Supplementary Material should be uploaded separately on submission, if there are
Supplementary Figures, please include the caption in the same file as the
figure. LaTeX Supplementary Material templates can be found in the Frontiers
LaTeX folder

# References

# Figures {-}


# Suplmentary materials

## List of species

```{r Species_list ,cache=TRUE}
a <- readRDS("Solutionnandes_linear_mp.rds") %>% purrr::reduce(bind_rows) %>% group_by(Spp) %>% summarise(n = n()) %>% arrange(Spp) %>% pull(Spp) %>% str_replace("_", " ")
```

The species used for the solution were the folowing:

`r a`




Soils Variables. The following soils variables were also used in species distribution models.  All variables were obtained from Soilgrids (67).  Variables with multiple strata available are the mean of the top 1m (strata 1-4). --> -->
* depth to bedrock
* pH 
* clay proportion     
* silt proportion 
* bulk density 



<!--  Prioritization under Climate Change. Zonation Conservation Planning Software is a widely used tool that allows for simultaneous prioritization of many thousands of conservation features (i.e. species or ecosystem types) while also considering fundamental aspects of the landscape including habitat condition, connectivity, and cost (68-69).  Zonation can be used for conservation prioritization under climate change as conservation features may be explicitly linked through interaction.  This allows for simultaneous prioritization of a species current range, its modeled future range, and the connectivity between the two limited by a species’ capacity to disperse.  The protocol for running Zonation under uncertain climate change projections is thoroughly described in Kujala et al. 2013 (70). --> -->

<!--  Species current ranges were linked to projected future ranges through an interaction layer. This layer is transformed by a dispersal kernel with a parameter to limit the interaction to the species total capacity to disperse over the period of analysis. Total dispersal capacity was assumed to be 100km for vertebrates (roughly 1 km/yr) and 1km for vascular plants (roughly 100m/yr). The algorithm favors areas of the species range in baseline climate that are retained in the projected future climate (i.e. the areas are suitable for species in both baseline and future climate). Prioritization were conducted using the mean projected future species ranges across 10 GCM under the same RCP (RCP2.6 or RCP8.5) that were discounted by the standard deviation the projected ranges.  Prioritizations were also run for each GCM individually for both RCP2.6 and RCP8.5 --> -->



<!--  Conservation Features. All available species models (vascular plants and vertebrates) were used in continental scale prioritizations.  Prioritization used the continuous value output of species distribution models for current climates and projected future climates. See species distribution modeling section above for more information. Models were fit at 30 arc-second resolution and were projected into 5km resolution environmental layers. All available species models (vascular plants and vertebrates) were used in continental scale prioritizations.  Species with too few occurrence records to produce a model were included as point locations (Zonation term = “Species of Special Interest”). Equal weighting was used for all conservation features. --> -->


### Prioritization Methods. 

Zonation ranks all cells in a landscape according to their value and removes cells of lowest value at each processing step.  Values are then recalculated for all remaining cells at each step. Core area zonation removal algorithm was used this assigns value to a cell from the highest value species present in that cell at each step of removal.  Species with smaller ranges have few cells that are critical for their conservation these cells therefore tend to have high values. By contrast, wide ranging species have more opportunities to be conserved -- so are typically lower value until only the core range remains. Warp factor (number of cells removed at each step) for all analysis was set to 1 to maximize the accuracy of the rank order assigned. All prioritizations used edge removal and boundary length penalty of 1.

Land Cover and Land Use. Areas of existing built up land or intensive agriculture were removed from the analysis and therefore those cells are not part of the prioritization solution.  Built up and agricultural areas were defined as >50% of pixel coverage for ‘urban’ and ‘agriculture’ classes from the 1km global consensus land cover dataset produced by Tuanmu et al. 2014 (71). Existing protected areas (40) are solved first so that the priorities take existing protection into account. 

